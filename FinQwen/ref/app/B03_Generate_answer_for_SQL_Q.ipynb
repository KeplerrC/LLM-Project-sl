{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656c8c8e-bd4d-4d24-8519-aa6078d5966e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:41.633749Z",
     "iopub.status.busy": "2024-07-04T11:30:41.633615Z",
     "iopub.status.idle": "2024-07-04T11:30:41.904244Z",
     "shell.execute_reply": "2024-07-04T11:30:41.903731Z",
     "shell.execute_reply.started": "2024-07-04T11:30:41.633734Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702f21d0-326b-400c-91f8-8019dbcc487c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:41.905714Z",
     "iopub.status.busy": "2024-07-04T11:30:41.905434Z",
     "iopub.status.idle": "2024-07-04T11:30:41.909235Z",
     "shell.execute_reply": "2024-07-04T11:30:41.908761Z",
     "shell.execute_reply.started": "2024-07-04T11:30:41.905697Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "deny_list = ['0','1','2','3','4','5','6','7','8','9','，','？','。',\n",
    "             '一','二','三','四','五','六','七','八','九','零','十',\n",
    "            '的','小','请','.','?','有多少','帮我','我想','知道',\n",
    "             '是多少','保留','是什么','-','(',')','（','）','：',\n",
    "              '哪个','统计','且','和','来','请问','记得','有','它们']\n",
    "pattern1 = r'\\d{8}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46683119-1d15-4830-b7e8-c82ee518b683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:41.909951Z",
     "iopub.status.busy": "2024-07-04T11:30:41.909802Z",
     "iopub.status.idle": "2024-07-04T11:30:41.919665Z",
     "shell.execute_reply": "2024-07-04T11:30:41.919201Z",
     "shell.execute_reply.started": "2024-07-04T11:30:41.909937Z"
    }
   },
   "outputs": [],
   "source": [
    "data_file_dir = '/mnt/workspace/intermediate/question_SQL_V6_exed.csv'\n",
    "data_file = pd.read_csv(data_file_dir,delimiter = \",\",header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277d760e-90da-4539-8d9a-3b393b290323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:41.920422Z",
     "iopub.status.busy": "2024-07-04T11:30:41.920216Z",
     "iopub.status.idle": "2024-07-04T11:30:41.926765Z",
     "shell.execute_reply": "2024-07-04T11:30:41.926300Z",
     "shell.execute_reply.started": "2024-07-04T11:30:41.920400Z"
    }
   },
   "outputs": [],
   "source": [
    "data_file2_dir = '/mnt/workspace/intermediate/A01_question_classify.csv'\n",
    "data_file2 = pd.read_csv(data_file2_dir,delimiter = \",\",header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c27d143-c308-4db1-ac7e-79efe436ab82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:41.927407Z",
     "iopub.status.busy": "2024-07-04T11:30:41.927270Z",
     "iopub.status.idle": "2024-07-04T11:30:43.837603Z",
     "shell.execute_reply": "2024-07-04T11:30:43.837118Z",
     "shell.execute_reply.started": "2024-07-04T11:30:41.927393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 19:30:42,981 - modelscope - INFO - PyTorch version 2.3.1 Found.\n",
      "2024-07-04 19:30:42,982 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2024-07-04 19:30:43,010 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 3b674e250eaff3ed305bb955cabf2c95 and a total number of 980 components indexed\n",
      "/root/miniconda3/envs/qwen/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer, snapshot_download\n",
    "from modelscope import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f396684a-4c72-4a64-ab07-8153b6c808d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:43.838522Z",
     "iopub.status.busy": "2024-07-04T11:30:43.838276Z",
     "iopub.status.idle": "2024-07-04T11:30:44.272836Z",
     "shell.execute_reply": "2024-07-04T11:30:44.272354Z",
     "shell.execute_reply.started": "2024-07-04T11:30:43.838505Z"
    }
   },
   "outputs": [],
   "source": [
    "# TDOO 原版用14B-Chat，太大加载不了，只能换Int4版本\n",
    "model_dir = '/mnt/workspace/Tongyi-Finance-14B-Chat-Int4'\n",
    "# Note: The default behavior now has injection attack prevention off.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3897f1b-b5df-485b-b61f-ac4099904dfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:44.274659Z",
     "iopub.status.busy": "2024-07-04T11:30:44.274432Z",
     "iopub.status.idle": "2024-07-04T11:30:50.986360Z",
     "shell.execute_reply": "2024-07-04T11:30:50.985899Z",
     "shell.execute_reply.started": "2024-07-04T11:30:44.274643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: please make sure that you are using the latest codes and checkpoints, especially if you used Qwen-7B before 09.25.2023.请使用最新模型和代码，尤其如果你在9月25日前已经开始使用Qwen-7B，千万注意不要使用错误代码和模型。\n",
      "CUDA extension not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B03_model_loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1e-05` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:407: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"cuda:0\", trust_remote_code=True, \n",
    "                                             # bf16=True\n",
    "                                            ).eval()\n",
    "\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_dir,\n",
    "                                                           trust_remote_code=True,\n",
    "                                                           temperature = 0.00001,\n",
    "                                                           top_p = 1,\n",
    "                                                           do_sample = False,\n",
    "                                                           seed = 1234)\n",
    "print('B03_model_loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934a28c5-ab13-4240-90b8-cca9c4426f47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:50.987454Z",
     "iopub.status.busy": "2024-07-04T11:30:50.986981Z",
     "iopub.status.idle": "2024-07-04T11:30:50.993170Z",
     "shell.execute_reply": "2024-07-04T11:30:50.992784Z",
     "shell.execute_reply.started": "2024-07-04T11:30:50.987436Z"
    }
   },
   "outputs": [],
   "source": [
    "deny_token_list = list()\n",
    "for word in deny_list:\n",
    "    temp_tokens = tokenizer(word)\n",
    "    temp_tokens = temp_tokens['input_ids']\n",
    "    deny_token_list = deny_token_list + temp_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26c90642-a794-4c31-b1d8-7731741f795a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:50.993976Z",
     "iopub.status.busy": "2024-07-04T11:30:50.993702Z",
     "iopub.status.idle": "2024-07-04T11:30:50.997074Z",
     "shell.execute_reply": "2024-07-04T11:30:50.996691Z",
     "shell.execute_reply.started": "2024-07-04T11:30:50.993962Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prompt_v33(question,data,index_list):\n",
    "    \n",
    "    Examples = '以下是一些例子：'\n",
    "    for index in index_list:\n",
    "        Examples = Examples + \"问题：\" + example_question_list[index] + '\\n'\n",
    "        Examples = Examples + \"资料：\" + example_data_list[index] + '\\n'\n",
    "        Examples = Examples + \"答案：\" + example_FA_list[index] + '\\n'\n",
    "    impt2 = \"\"\"\n",
    "        你要进行句子生成工作，根据提供的资料来回答对应的问题。下面是一些例子。注意问题中对小数位数的要求。+ '\\n'\n",
    "    \"\"\"\n",
    "    \n",
    "                \n",
    "    impt2 = impt2 + Examples\n",
    "\n",
    "    impt2 = impt2 +  \"问题：\" + question + '\\n'\n",
    "    impt2 = impt2 +  \"资料：\" + data + '\\n'\n",
    "    impt2 = impt2 +  \"答案：\"\n",
    "    return impt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58d66803-cac1-4c98-90b2-9e7952caadd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:50.997821Z",
     "iopub.status.busy": "2024-07-04T11:30:50.997675Z",
     "iopub.status.idle": "2024-07-04T11:30:51.003609Z",
     "shell.execute_reply": "2024-07-04T11:30:51.003216Z",
     "shell.execute_reply.started": "2024-07-04T11:30:50.997808Z"
    }
   },
   "outputs": [],
   "source": [
    "SQL_examples_file_dir = \"/mnt/workspace/files/ICL_EXP.csv\"\n",
    "SQL_examples_file = pd.read_csv(SQL_examples_file_dir,delimiter = \",\",header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49737ac4-254b-4149-8e57-936584981711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:51.004224Z",
     "iopub.status.busy": "2024-07-04T11:30:51.004083Z",
     "iopub.status.idle": "2024-07-04T11:30:51.006512Z",
     "shell.execute_reply": "2024-07-04T11:30:51.006133Z",
     "shell.execute_reply.started": "2024-07-04T11:30:51.004211Z"
    }
   },
   "outputs": [],
   "source": [
    "example_employ_list = list()\n",
    "for cyc in range(len(SQL_examples_file)):\n",
    "    example_employ_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87d9ee74-cde0-4820-b3be-705182d6a4b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:51.007299Z",
     "iopub.status.busy": "2024-07-04T11:30:51.007155Z",
     "iopub.status.idle": "2024-07-04T11:30:51.064450Z",
     "shell.execute_reply": "2024-07-04T11:30:51.064067Z",
     "shell.execute_reply.started": "2024-07-04T11:30:51.007286Z"
    }
   },
   "outputs": [],
   "source": [
    "example_question_list = list()\n",
    "example_data_list = list()\n",
    "example_FA_list = list()\n",
    "example_token_list = list()\n",
    "\n",
    "for cyc in range(len(SQL_examples_file)):\n",
    "    example_question_list.append(SQL_examples_file[cyc:cyc+1]['问题'][cyc])\n",
    "    example_data_list.append(SQL_examples_file[cyc:cyc+1]['资料'][cyc])\n",
    "    example_FA_list.append(SQL_examples_file[cyc:cyc+1]['FA'][cyc])\n",
    "    temp_tokens = tokenizer(SQL_examples_file[cyc:cyc+1]['问题'][cyc])\n",
    "    temp_tokens = temp_tokens['input_ids']\n",
    "    temp_tokens2 = [x for x in temp_tokens if x not in deny_token_list]\n",
    "    example_token_list.append(temp_tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af5fb1eb-7cba-4def-91cd-74c5782531e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:51.065237Z",
     "iopub.status.busy": "2024-07-04T11:30:51.064972Z",
     "iopub.status.idle": "2024-07-04T11:30:51.070561Z",
     "shell.execute_reply": "2024-07-04T11:30:51.070188Z",
     "shell.execute_reply.started": "2024-07-04T11:30:51.065224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = open('/mnt/workspace/intermediate/FA_V5_SQL.csv', 'w', newline='', encoding = 'utf-8-sig') \n",
    "csvwriter = csv.writer(g)\n",
    "csvwriter.writerow(['问题id','问题','FA','SQL结果'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69c83b53-216c-491c-b7bf-2c5ec92527ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T11:30:51.071197Z",
     "iopub.status.busy": "2024-07-04T11:30:51.071051Z",
     "iopub.status.idle": "2024-07-04T15:05:12.229358Z",
     "shell.execute_reply": "2024-07-04T15:05:12.228792Z",
     "shell.execute_reply.started": "2024-07-04T11:30:51.071184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/root/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1e-05` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:407: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 49/1000 [11:08<2:06:26,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [21:28<2:14:17,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 148/1000 [33:01<2:30:13, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 199/1000 [43:23<3:20:36, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 249/1000 [53:35<2:21:52, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [1:05:02<3:49:06, 19.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 350/1000 [1:15:49<1:57:49, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 398/1000 [1:26:56<3:14:42, 19.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 449/1000 [1:39:47<3:16:21, 21.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/1000 [1:52:55<3:19:36, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 550/1000 [2:04:28<1:51:01, 14.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 600/1000 [2:15:38<1:47:23, 16.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 649/1000 [2:25:37<1:12:01, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 699/1000 [2:34:57<36:04,  7.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 750/1000 [2:43:51<51:47, 12.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 799/1000 [2:52:53<23:59,  7.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 850/1000 [3:02:46<37:26, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [3:14:28<35:36, 21.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 950/1000 [3:23:51<06:35,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [3:34:21<00:00, 12.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for cyc in tqdm(range(1000)):\n",
    "    if cyc % 50 == 0:\n",
    "        print(cyc)\n",
    "    temp_question = data_file[cyc:cyc+1]['问题'][cyc]\n",
    "    class_ans = data_file2[cyc:cyc+1]['分类'][cyc]\n",
    "    SQL_search_result = data_file[cyc:cyc+1]['执行结果'][cyc]\n",
    "    temp_FA = temp_question\n",
    "    if class_ans != 'SQL':\n",
    "        temp_FA = 'N_A'\n",
    "    elif SQL_search_result != 'N_A':\n",
    "        if len(SQL_search_result) > 0:\n",
    "            if len(SQL_search_result) > 250:\n",
    "                SQL_search_result = SQL_search_result[0:250]\n",
    "            temp_question = data_file[cyc:cyc+1]['问题'][cyc]\n",
    "            date_list =  re.findall(pattern1,temp_question)\n",
    "            temp_question2_for_search = temp_question\n",
    "            for t_date in date_list:\n",
    "                temp_question2_for_search.replace(t_date,' ')\n",
    "            temp_tokens = tokenizer(temp_question2_for_search)\n",
    "            temp_tokens = temp_tokens['input_ids']\n",
    "            temp_tokens2 = [x for x in temp_tokens if x not in deny_token_list]\n",
    "            temp_tokens = temp_tokens2\n",
    "            #计算与已有问题的相似度\n",
    "            similarity_list = list()\n",
    "            for cyc2 in range(len(SQL_examples_file)):\n",
    "                similarity_list.append(len(set(temp_tokens) &set(example_token_list[cyc2]))/ (len(set(temp_tokens))+len(set(example_token_list[cyc2])) ))\n",
    "\n",
    "            #求与第X个问题相似的问题\n",
    "\n",
    "            t = copy.deepcopy(similarity_list)\n",
    "            # 求m个最大的数值及其索引\n",
    "            max_number = []\n",
    "            max_index = []\n",
    "            for _ in range(n):\n",
    "                number = max(t)\n",
    "                index = t.index(number)\n",
    "                t[index] = 0\n",
    "                max_number.append(number)\n",
    "                max_index.append(index)\n",
    "            t = []\n",
    "                \n",
    "                \n",
    "                \n",
    "            prompt2 = get_prompt_v33(data_file['问题'][cyc],data_file['执行结果'][cyc],max_index)\n",
    "            temp_FA, history = model.chat(tokenizer, prompt2, history=None)\n",
    "\n",
    "            \n",
    "    else:\n",
    "        SQL_search_result = 'SQL未能成功执行！'\n",
    "        \n",
    "    \n",
    "    csvwriter.writerow([str(data_file[cyc:(cyc+1)]['问题id'][cyc]),\n",
    "                    str(data_file[cyc:(cyc+1)]['问题'][cyc]),temp_FA,SQL_search_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ce6483-98bc-4f92-b255-c4e505430ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T15:05:12.230658Z",
     "iopub.status.busy": "2024-07-04T15:05:12.230197Z",
     "iopub.status.idle": "2024-07-04T15:05:12.233358Z",
     "shell.execute_reply": "2024-07-04T15:05:12.232857Z",
     "shell.execute_reply.started": "2024-07-04T15:05:12.230633Z"
    }
   },
   "outputs": [],
   "source": [
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c1e3d-cb3c-42ee-8a4f-502543d9fd90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4f638-54f7-4fb9-a19e-f7474794260e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3cb59-cf4e-428f-bcd4-f67408e63490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf08e8a-a0ec-474c-b9f6-ff1e79db6d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f28418b-a9a9-40a3-aec3-1f1a84c63095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf93c12-3a04-46ce-b3b0-c5457217a768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426cc6e1-7498-427a-bd46-2269e48b14de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674d4b6-304d-4b13-9680-184ea8fad288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1551b-848d-4d15-a105-92f6eea0e823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10a015-dd46-4d36-964b-0f51be9df30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen",
   "language": "python",
   "name": "qwen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
