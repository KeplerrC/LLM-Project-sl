{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795e1794-9805-44d2-a476-2c32ee0f8850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:04.110911Z",
     "iopub.status.busy": "2024-06-15T20:31:04.110739Z",
     "iopub.status.idle": "2024-06-15T20:31:04.117882Z",
     "shell.execute_reply": "2024-06-15T20:31:04.116907Z",
     "shell.execute_reply.started": "2024-06-15T20:31:04.110891Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366c21fe-091b-4f8d-8711-65dc60faf314",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:04.118701Z",
     "iopub.status.busy": "2024-06-15T20:31:04.118532Z",
     "iopub.status.idle": "2024-06-15T20:31:06.960779Z",
     "shell.execute_reply": "2024-06-15T20:31:06.960261Z",
     "shell.execute_reply.started": "2024-06-15T20:31:04.118682Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"medical_zh/train_zh_0.jsonl\", \"r\") as f:\n",
    "    lst = [json.loads(item) for item in f.readlines()[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d4928d-91e5-434d-94bc-d9484e23ad94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:06.961942Z",
     "iopub.status.busy": "2024-06-15T20:31:06.961490Z",
     "iopub.status.idle": "2024-06-15T20:31:06.967424Z",
     "shell.execute_reply": "2024-06-15T20:31:06.966880Z",
     "shell.execute_reply.started": "2024-06-15T20:31:06.961914Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '血热的临床表现是什么?',\n",
       " 'input': '',\n",
       " 'output': '初发或复发病不久。皮疹发展迅速，呈点滴状、钱币状或混合状。常见丘疹、斑丘疹、大小不等的斑片，潮红、鲜红或深红色。散布于体表各处或几处，以躯干、四肢多见，亦可先从头面开始，逐渐发展至全身。新皮疹不断出现，表面覆有银白色鳞屑，干燥易脱落，剥刮后有点状出血。可有同形反应;伴瘙痒、心烦口渴。大便秘结、小便短黄，舌质红赤，苔薄黄或根部黄厚，脉弦滑或滑数。血热炽盛病机，主要表现在如下四个面：一、热象：血热多属阳盛则热之实性、热性病机和病证、并表现出热象。二、血行加速：血得热则行，可使血流加速，且使脉道扩张，络脉充血，故可见面红目赤，舌色深红（即舌绛）等症。三、动血：在血行加速与脉道扩张的基础上，血分有热，可灼伤脉络，引起出血，称为“热迫血妄行”，或称动血。四、扰乱心神：血热炽盛则扰动心神，心主血脉而藏神，血脉与心相通，故血热则使心神不安，而见心烦，或躁扰发狂等症。'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592c3b1e-0698-4d22-be1a-389dad29ed17",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:06.969192Z",
     "iopub.status.busy": "2024-06-15T20:31:06.968870Z",
     "iopub.status.idle": "2024-06-15T20:31:06.978501Z",
     "shell.execute_reply": "2024-06-15T20:31:06.978029Z",
     "shell.execute_reply.started": "2024-06-15T20:31:06.969171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"train_lora.json\", \"w\") as f:\n",
    "    json.dump(lst, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385237af-22f7-453a-b8cb-cb975f5dc2e9",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:06.979376Z",
     "iopub.status.busy": "2024-06-15T20:31:06.979087Z",
     "iopub.status.idle": "2024-06-15T20:31:07.634542Z",
     "shell.execute_reply": "2024-06-15T20:31:07.633960Z",
     "shell.execute_reply.started": "2024-06-15T20:31:06.979358Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/qwen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "df = pd.read_json('train_lora.json')\n",
    "ds = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d41e913-c1d1-4a2d-ab1d-bb499a6383a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:07.635466Z",
     "iopub.status.busy": "2024-06-15T20:31:07.635276Z",
     "iopub.status.idle": "2024-06-15T20:31:07.639192Z",
     "shell.execute_reply": "2024-06-15T20:31:07.638643Z",
     "shell.execute_reply.started": "2024-06-15T20:31:07.635447Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '血热的临床表现是什么?',\n",
       " 'input': '',\n",
       " 'output': '初发或复发病不久。皮疹发展迅速，呈点滴状、钱币状或混合状。常见丘疹、斑丘疹、大小不等的斑片，潮红、鲜红或深红色。散布于体表各处或几处，以躯干、四肢多见，亦可先从头面开始，逐渐发展至全身。新皮疹不断出现，表面覆有银白色鳞屑，干燥易脱落，剥刮后有点状出血。可有同形反应;伴瘙痒、心烦口渴。大便秘结、小便短黄，舌质红赤，苔薄黄或根部黄厚，脉弦滑或滑数。血热炽盛病机，主要表现在如下四个面：一、热象：血热多属阳盛则热之实性、热性病机和病证、并表现出热象。二、血行加速：血得热则行，可使血流加速，且使脉道扩张，络脉充血，故可见面红目赤，舌色深红（即舌绛）等症。三、动血：在血行加速与脉道扩张的基础上，血分有热，可灼伤脉络，引起出血，称为“热迫血妄行”，或称动血。四、扰乱心神：血热炽盛则扰动心神，心主血脉而藏神，血脉与心相通，故血热则使心神不安，而见心烦，或躁扰发狂等症。'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d77ad6a-76cc-4f01-975c-7de99bb26edf",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:07.640136Z",
     "iopub.status.busy": "2024-06-15T20:31:07.639806Z",
     "iopub.status.idle": "2024-06-15T20:31:10.300566Z",
     "shell.execute_reply": "2024-06-15T20:31:10.300000Z",
     "shell.execute_reply.started": "2024-06-15T20:31:07.640117Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QWenTokenizer(name_or_path='Qwen-1_8B-Chat', vocab_size=151851, model_max_length=8192, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "\n",
    "ckpt = 'Qwen-1_8B-Chat'\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt, use_fast=False, trust_remote_code=True)\n",
    "tokenizer.pad_token_id = tokenizer.eod_id\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ac69645-ced1-482c-963c-8b000f01f6ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:10.301776Z",
     "iopub.status.busy": "2024-06-15T20:31:10.301376Z",
     "iopub.status.idle": "2024-06-15T20:31:10.306718Z",
     "shell.execute_reply": "2024-06-15T20:31:10.306219Z",
     "shell.execute_reply.started": "2024-06-15T20:31:10.301755Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 384    # Llama分词器会将一个中文字切分为多个token，因此需要放开一些最大长度，保证数据的完整性\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\"\\n\".join([\"<|im_start|>system\", \"你是一个医学助手，需要回答用户关于医学的问题：<|im_end|>\" + \"\\n<|im_start|>user\\n\" + example[\"instruction\"] + example[\"input\"] + \"<|im_end|>\\n\"]).strip(), add_special_tokens=False)  # add_special_tokens 不在开头加 special_tokens\n",
    "    response = tokenizer(\"<|im_start|>assistant\\n\" + example[\"output\"] + \"<|im_end|>\\n\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]  # 因为eos token咱们也是要关注的所以 补充为1\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]  # Qwen的特殊构造就是这样的\n",
    "    if len(input_ids) > MAX_LENGTH:  # 做一个截断\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664e4f18-844e-4d63-9598-7a123e76e2b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:10.307627Z",
     "iopub.status.busy": "2024-06-15T20:31:10.307457Z",
     "iopub.status.idle": "2024-06-15T20:31:12.313922Z",
     "shell.execute_reply": "2024-06-15T20:31:12.313420Z",
     "shell.execute_reply.started": "2024-06-15T20:31:10.307609Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 2442.86 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_id = ds.map(process_func, remove_columns=ds.column_names)\n",
    "tokenized_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983af593-f21e-428c-a553-b9475efa1c55",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:12.315047Z",
     "iopub.status.busy": "2024-06-15T20:31:12.314639Z",
     "iopub.status.idle": "2024-06-15T20:31:12.319149Z",
     "shell.execute_reply": "2024-06-15T20:31:12.318669Z",
     "shell.execute_reply.started": "2024-06-15T20:31:12.315027Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n你是一个医学助手，需要回答用户关于医学的问题：<|im_end|>\\n<|im_start|>user\\n帕金森叠加综合征的辅助治疗有些什么？<|im_end|><|im_start|>assistant\\n综合治疗；康复训练；生活护理指导；低频重复经颅磁刺激治疗<|im_end|>\\n<|endoftext|>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_id[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc6ca59-bf3f-43b6-804d-75b04e39181c",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:12.320357Z",
     "iopub.status.busy": "2024-06-15T20:31:12.319784Z",
     "iopub.status.idle": "2024-06-15T20:31:12.324230Z",
     "shell.execute_reply": "2024-06-15T20:31:12.323739Z",
     "shell.execute_reply.started": "2024-06-15T20:31:12.320337Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>assistant\\n综合治疗；康复训练；生活护理指导；低频重复经颅磁刺激治疗<|im_end|>\\n<|endoftext|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(filter(lambda x: x != -100, tokenized_id[1][\"labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "886ac5ed-f347-434b-9a61-3de4b1f5ab7e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:12.325158Z",
     "iopub.status.busy": "2024-06-15T20:31:12.324839Z",
     "iopub.status.idle": "2024-06-15T20:31:15.106067Z",
     "shell.execute_reply": "2024-06-15T20:31:15.105547Z",
     "shell.execute_reply.started": "2024-06-15T20:31:12.325140Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QWenLMHeadModel(\n",
       "  (transformer): QWenModel(\n",
       "    (wte): Embedding(151936, 2048)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (rotary_emb): RotaryEmbedding()\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x QWenBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): QWenAttention(\n",
       "          (c_attn): Linear8bitLt(in_features=2048, out_features=6144, bias=True)\n",
       "          (c_proj): Linear8bitLt(in_features=2048, out_features=2048, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): QWenMLP(\n",
       "          (w1): Linear8bitLt(in_features=2048, out_features=5504, bias=False)\n",
       "          (w2): Linear8bitLt(in_features=2048, out_features=5504, bias=False)\n",
       "          (c_proj): Linear8bitLt(in_features=5504, out_features=2048, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(ckpt, trust_remote_code=True, torch_dtype=torch.half, load_in_8bit=True, device_map=\"auto\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8a1879-ef9f-48af-93b4-34093b0527ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:15.108437Z",
     "iopub.status.busy": "2024-06-15T20:31:15.108039Z",
     "iopub.status.idle": "2024-06-15T20:31:15.110983Z",
     "shell.execute_reply": "2024-06-15T20:31:15.110491Z",
     "shell.execute_reply.started": "2024-06-15T20:31:15.108417Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.enable_input_require_grads() # 开启梯度检查点时，要执行该方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8302abe0-7005-43fb-b3d8-5fb87e79c22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:15.112038Z",
     "iopub.status.busy": "2024-06-15T20:31:15.111691Z",
     "iopub.status.idle": "2024-06-15T20:31:15.115303Z",
     "shell.execute_reply": "2024-06-15T20:31:15.114803Z",
     "shell.execute_reply.started": "2024-06-15T20:31:15.112019Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4b4a7f-bdb6-4479-8cc7-fc19afbc66e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:15.116261Z",
     "iopub.status.busy": "2024-06-15T20:31:15.115910Z",
     "iopub.status.idle": "2024-06-15T20:31:15.120563Z",
     "shell.execute_reply": "2024-06-15T20:31:15.120024Z",
     "shell.execute_reply.started": "2024-06-15T20:31:15.116242Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules={'w1', 'c_proj', 'w2', 'c_attn'}, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    target_modules=[\"c_attn\", \"c_proj\", \"w1\", \"w2\"],\n",
    "    inference_mode=False, # 训练模式\n",
    "    r=8, # Lora 秩\n",
    "    lora_alpha=32, # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1# Dropout 比例\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d11f708a-1547-447a-85e1-22bcf3b304d6",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:15.121320Z",
     "iopub.status.busy": "2024-06-15T20:31:15.121150Z",
     "iopub.status.idle": "2024-06-15T20:31:15.290822Z",
     "shell.execute_reply": "2024-06-15T20:31:15.290331Z",
     "shell.execute_reply.started": "2024-06-15T20:31:15.121302Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): QWenLMHeadModel(\n",
       "      (transformer): QWenModel(\n",
       "        (wte): Embedding(151936, 2048)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (h): ModuleList(\n",
       "          (0-23): 24 x QWenBlock(\n",
       "            (ln_1): RMSNorm()\n",
       "            (attn): QWenAttention(\n",
       "              (c_attn): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=2048, out_features=6144, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=6144, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ln_2): RMSNorm()\n",
       "            (mlp): QWenMLP(\n",
       "              (w1): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=2048, out_features=5504, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=5504, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (w2): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=2048, out_features=5504, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=5504, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=5504, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5504, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): RMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_peft_model(model, config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2465ce6c-cc8d-4238-aa91-04488448b28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:15.291650Z",
     "iopub.status.busy": "2024-06-15T20:31:15.291475Z",
     "iopub.status.idle": "2024-06-15T20:31:15.297203Z",
     "shell.execute_reply": "2024-06-15T20:31:15.296626Z",
     "shell.execute_reply.started": "2024-06-15T20:31:15.291632Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,709,248 || all params: 1,843,537,920 || trainable%: 0.3639\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd101b3-533f-427b-8755-0fd1ca950b5b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:15.298143Z",
     "iopub.status.busy": "2024-06-15T20:31:15.297807Z",
     "iopub.status.idle": "2024-06-15T20:31:15.310220Z",
     "shell.execute_reply": "2024-06-15T20:31:15.309762Z",
     "shell.execute_reply.started": "2024-06-15T20:31:15.298112Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=f\"./output/{ckpt}_old\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=12,\n",
    "    gradient_checkpointing=True,\n",
    "    save_steps=186,\n",
    "    learning_rate=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8018d28-5c2d-4b0c-b132-4ff409e92731",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:15.311183Z",
     "iopub.status.busy": "2024-06-15T20:31:15.310819Z",
     "iopub.status.idle": "2024-06-15T20:31:15.319570Z",
     "shell.execute_reply": "2024-06-15T20:31:15.319111Z",
     "shell.execute_reply.started": "2024-06-15T20:31:15.311165Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/qwen/lib/python3.10/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbc183bf-37c3-481f-bda4-323e249caaa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:31:15.320325Z",
     "iopub.status.busy": "2024-06-15T20:31:15.320157Z",
     "iopub.status.idle": "2024-06-15T21:04:37.360898Z",
     "shell.execute_reply": "2024-06-15T21:04:37.359986Z",
     "shell.execute_reply.started": "2024-06-15T20:31:15.320307Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='744' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [744/744 33:19, Epoch 11/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.584600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.925900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.899100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.933400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.904500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.755700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.853200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.822300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.784800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.546500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.612200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.602300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.704400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.593600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.582300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.371600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.521400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.571300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.340700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.348200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.383000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.370300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.262600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.304400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.261100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.257100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.140200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.115900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.029300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.050900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.087100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.955900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.991400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.940200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.877200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.910500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.890400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.880700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.883300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.968400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.700900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.752800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.696200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.755300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.874500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/qwen/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen-1_8B-Chat/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4d9af09c30>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: d91a59da-6f18-4cb7-a80d-6d88f4b2456b)') - silently ignoring the lookup for the file config.json in Qwen-1_8B-Chat.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in Qwen-1_8B-Chat - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen-1_8B-Chat/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4d9adae590>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 84691cb2-da91-40bf-b094-3ac98ec9ce42)') - silently ignoring the lookup for the file config.json in Qwen-1_8B-Chat.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in Qwen-1_8B-Chat - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen-1_8B-Chat/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4d9af16da0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: c6c43b1b-7add-444e-acce-635c33e17467)') - silently ignoring the lookup for the file config.json in Qwen-1_8B-Chat.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in Qwen-1_8B-Chat - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen-1_8B-Chat/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f4d9ae57280>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 613aace0-2c59-4db4-a6d2-af9596d75ec0)') - silently ignoring the lookup for the file config.json in Qwen-1_8B-Chat.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in Qwen-1_8B-Chat - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=744, training_loss=1.3652763059062343, metrics={'train_runtime': 2001.8862, 'train_samples_per_second': 5.994, 'train_steps_per_second': 0.372, 'total_flos': 3.072383330992128e+16, 'train_loss': 1.3652763059062343, 'epoch': 11.9})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08d34436-5110-4612-943b-103685b6fed4",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-06-15T21:04:37.363061Z",
     "iopub.status.busy": "2024-06-15T21:04:37.362135Z",
     "iopub.status.idle": "2024-06-15T21:04:43.369432Z",
     "shell.execute_reply": "2024-06-15T21:04:43.368895Z",
     "shell.execute_reply.started": "2024-06-15T21:04:37.363021Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/pai/envs/qwen/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A1] query='帕金森叠加综合征的辅助治疗有些什么?' history=[] system='你是一个医学助手，需要回答用户关于医学的问题：' max_window_size=6144\n",
      "[A2] raw_text='<|im_start|>system\\n你是一个医学助手，需要回答用户关于医学的问题：<|im_end|>\\n<|im_start|>user\\n帕金森叠加综合征的辅助治疗有些什么?<|im_end|>\\n<|im_start|>assistant\\n' context_tokens=[151644, 8948, 198, 56568, 101909, 104316, 110498, 3837, 85106, 102104, 20002, 101888, 104316, 103936, 5122, 151645, 198, 151644, 872, 198, 105091, 34230, 100739, 110081, 118458, 9370, 104650, 101899, 101895, 99245, 30, 151645, 198, 151644, 77091, 198]\n",
      "\n",
      "[B1] input_ids=tensor([[151644,   8948,    198,  56568, 101909, 104316, 110498,   3837,  85106,\n",
      "         102104,  20002, 101888, 104316, 103936,   5122, 151645,    198, 151644,\n",
      "            872,    198, 105091,  34230, 100739, 110081, 118458,   9370, 104650,\n",
      "         101899, 101895,  99245,     30, 151645,    198, 151644,  77091,    198]],\n",
      "       device='cuda:0') stop_words_ids=[[151645], [151644]] generation_config=GenerationConfig {\n",
      "  \"chat_format\": \"chatml\",\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"max_new_tokens\": 512,\n",
      "  \"max_window_size\": 6144,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"top_k\": 0,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n",
      "[B2] outputs=tensor([[151644,   8948,    198,  56568, 101909, 104316, 110498,   3837,  85106,\n",
      "         102104,  20002, 101888, 104316, 103936,   5122, 151645,    198, 151644,\n",
      "            872,    198, 105091,  34230, 100739, 110081, 118458,   9370, 104650,\n",
      "         101899, 101895,  99245,     30, 151645,    198, 151644,  77091,    198,\n",
      "          99285,  64952, 105444,  53393, 114993, 101459, 104313, 101899,  24968,\n",
      "         102035,  99799, 105841, 101899,  24968,  99285,  72586,  51232, 105444,\n",
      "          53393, 114993, 101459, 104313, 101899,      7, 105184,   1215, 102035,\n",
      "          99799, 105841, 101899, 151645, 151643]], device='cuda:0')\n",
      "\n",
      "[C1] tensor([151644,   8948,    198,  56568, 101909, 104316, 110498,   3837,  85106,\n",
      "        102104,  20002, 101888, 104316, 103936,   5122, 151645,    198, 151644,\n",
      "           872,    198, 105091,  34230, 100739, 110081, 118458,   9370, 104650,\n",
      "        101899, 101895,  99245,     30, 151645,    198, 151644,  77091,    198,\n",
      "         99285,  64952, 105444,  53393, 114993, 101459, 104313, 101899,  24968,\n",
      "        102035,  99799, 105841, 101899,  24968,  99285,  72586,  51232, 105444,\n",
      "         53393, 114993, 101459, 104313, 101899,      7, 105184,   1215, 102035,\n",
      "         99799, 105841, 101899, 151645, 151643], device='cuda:0'), len(raw_text)=121 len(context_tokens)=36\n",
      "[C2] response='低频重复经颅磁刺激治疗；配合综合康复治疗；低引产重复经颅磁刺激治疗(早期);配合综合康复治疗'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('低频重复经颅磁刺激治疗；配合综合康复治疗；低引产重复经颅磁刺激治疗(早期);配合综合康复治疗',\n",
       " [('帕金森叠加综合征的辅助治疗有些什么?', '低频重复经颅磁刺激治疗；配合综合康复治疗；低引产重复经颅磁刺激治疗(早期);配合综合康复治疗')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"帕金森叠加综合征的辅助治疗有些什么?\", history=[], system=\"你是一个医学助手，需要回答用户关于医学的问题：\")\n",
    "response, history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen",
   "language": "python",
   "name": "qwen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
